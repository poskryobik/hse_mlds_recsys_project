{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gdown \n",
    "import seaborn as sns\n",
    "import scipy.sparse as sps\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.sparse import hstack, vstack "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=1D2WB0E7FEHrYHpiXMYezo_Gx8UFGg0_H\n",
      "To: c:\\code\\rec_sys\\hse_mlds_recsys_project\\ML\\rating_matrix.npz\n",
      "100%|██████████| 19.5M/19.5M [00:01<00:00, 10.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка матрицы с рейтингами\n",
    "gdown.download(url=\"https://drive.google.com/uc?export=download&id=1D2WB0E7FEHrYHpiXMYezo_Gx8UFGg0_H\",  \n",
    "               output=\"rating_matrix.npz\",\n",
    "               quiet=False)\n",
    "# Импорт матрицы\n",
    "rating_matrix = sps.load_npz(\"rating_matrix.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=1Ud6jFto6e7FW5y0LxxwX8afpmTrvA0u-\n",
      "To: c:\\code\\rec_sys\\hse_mlds_recsys_project\\ML\\test_transacrion_df.csv\n",
      "100%|██████████| 52.4M/52.4M [00:04<00:00, 11.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка тестовых данных\n",
    "gdown.download(url=\"https://drive.google.com/uc?export=download&id=1Ud6jFto6e7FW5y0LxxwX8afpmTrvA0u-\",  \n",
    "               output=\"test_transacrion_df.csv\",\n",
    "               quiet=False)\n",
    "# Загрузка датафрейма с тестовыми данными\n",
    "test_df = pd.read_csv(\"test_transacrion_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=1eodl9OlaYy3NTu9TpbtPLHNurXxeHlhh\n",
      "To: c:\\code\\rec_sys\\hse_mlds_recsys_project\\ML\\encoder.pkl\n",
      "100%|██████████| 800k/800k [00:00<00:00, 3.32MB/s]\n",
      "c:\\code\\rec_sys\\hse_mlds_recsys_project\\.conda\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Загрузка кодировщика user_id\n",
    "gdown.download(url=\"https://drive.google.com/uc?export=download&id=1eodl9OlaYy3NTu9TpbtPLHNurXxeHlhh\",  \n",
    "               output=\"encoder.pkl\",\n",
    "               quiet=False)\n",
    "# Загрузка кодировщика\n",
    "with open(\"encoder.pkl\", \"rb\") as f:\n",
    "    encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=1epGrpzB8BEC2t5Od3hrL3x07B1VZIm3c\n",
      "To: c:\\code\\rec_sys\\hse_mlds_recsys_project\\ML\\ratings.csv\n",
      "100%|██████████| 211M/211M [00:18<00:00, 11.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Загрузка датафрейма с рейтингами\n",
    "gdown.download(url=\"https://drive.google.com/uc?export=download&id=1epGrpzB8BEC2t5Od3hrL3x07B1VZIm3c\",  \n",
    "               output=\"ratings.csv\",\n",
    "               quiet=False)\n",
    "rating_df = pd.read_csv(\"ratings.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9137821x9137821 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9137821 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x49414 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9081563 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Целесообразно брать только непустые строки и столбцы \n",
    "cnt_users = rating_df['user_id'].nunique()\n",
    "cnt_items = rating_df['product_id'].nunique()\n",
    "# Ограничение матрицы с рейтингами\n",
    "rating_matrix = rating_matrix[:cnt_users, :cnt_items+1]\n",
    "rating_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрика качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(relevant, predicted, k: int = 10):\n",
    "    \"\"\" \n",
    "        Функиця расчета Precision@k\n",
    "        relevant - релевантные items для одного пользователя\n",
    "        predicted - рекомендованные items для одного пользователя\n",
    "    \"\"\"\n",
    "    return len(set(relevant[:k]) & set(predicted[:k]))/k \n",
    "\n",
    "def rel_item(relevant, predicted):\n",
    "    \"\"\"\n",
    "        Функция рассчитывает количество релевантных Item\n",
    "    \"\"\"\n",
    "    result = [0]*max(len(relevant), len(predicted))\n",
    "    items = min(len(relevant), len(predicted))\n",
    "    for i in range(items):\n",
    "        result[i] = int(relevant[i] == predicted[i])\n",
    "    return result  \n",
    "\n",
    "\n",
    "def ap_at_k(relevant, predicted, k: int = 10):\n",
    "    \"\"\" \n",
    "        Функция расчета AP@k\n",
    "        relevant - релевантные items для одного пользователя\n",
    "        predicted - рекомендованные items для одного пользователя\n",
    "    \"\"\"\n",
    "    y_i = rel_item(relevant=relevant, predicted=predicted)\n",
    "    p_at_i = [0]*k\n",
    "    iter_cnt = min(len(relevant), k)\n",
    "    for i in range(1, iter_cnt+1):\n",
    "        p_at_i[i-1] = precision_at_k(relevant=relevant, predicted=predicted, k=i)\n",
    "    return sum([y*p/k for y, p in zip(y_i, p_at_i)])\n",
    "\n",
    "def map_at_k(relevant, predicted, k: int = 10):\n",
    "    \"\"\" \n",
    "        Функция расчета MAP@k\n",
    "        relevant список по всем пользователям с их релевантными items\n",
    "        predicted список по всем пользователям с их рекомендованными items\n",
    "    \"\"\"\n",
    "    users = len(relevant)\n",
    "    sum_apk = 0\n",
    "    for user in range(users):\n",
    "        sum_apk += ap_at_k(relevant=relevant[user], predicted=predicted[user], k=k)\n",
    "    return sum_apk/users\n",
    "\n",
    "def nap_at_k(relevant, predicted, k: int = 10):\n",
    "    \"\"\" \n",
    "        Функция расчета normalize AP@k\n",
    "        relevant - релевантные items для одного пользователя\n",
    "        predicted - рекомендованные items для одного пользователя\n",
    "    \"\"\"\n",
    "    y_i = rel_item(relevant=relevant, predicted=predicted)\n",
    "    p_at_i = [0]*k\n",
    "    k = min(len(relevant), k)\n",
    "    for i in range(1, k+1):\n",
    "        p_at_i[i-1] = precision_at_k(relevant=relevant, predicted=predicted, k=i)\n",
    "    return sum([y*p/k for y, p in zip(y_i, p_at_i)])\n",
    "\n",
    "def mnap_at_k(relevant, predicted, k: int = 10):\n",
    "    \"\"\" \n",
    "        Функция расчета MAP@k\n",
    "        relevant список по всем пользователям с их релевантными items\n",
    "        predicted список по всем пользователям с их рекомендованными items\n",
    "    \"\"\"\n",
    "    users = len(relevant)\n",
    "    sum_napk = 0\n",
    "    for user in range(users):\n",
    "        sum_napk += nap_at_k(relevant=relevant[user], predicted=predicted[user], k=k)\n",
    "    return sum_napk/users\n",
    "\n",
    "def hitrate_at_k(relevant, predicted, k: int = 10):\n",
    "    \"\"\"\n",
    "        Функция расчета Hitrate@k\n",
    "        relevant список по всем пользователям с их релевантными items\n",
    "        predicted список по всем пользователям с их рекомендованными items\n",
    "    \"\"\"\n",
    "    \n",
    "    cnt_user = len(predicted) # Количество пользователей    \n",
    "    cnt_valid_user = 0\n",
    "    for user in range(cnt_user):\n",
    "        cnt_valid_user += int(len(set(relevant[user][:k]) & set(predicted[user][:k])) > 0) \n",
    "\n",
    "    return cnt_valid_user/cnt_user\n",
    "\n",
    "def ndsg_at_k(relevant, predicted, k: int = 10):\n",
    "    \"\"\"\n",
    "        Функция расчета nDSG@k\n",
    "        relevant - релевантные items для одного пользователя\n",
    "        predicted - рекомендованные items для одного пользователя\n",
    "    \"\"\"\n",
    "    idsg_at_k = sum([1/np.log2(k+1) for k in range(1, k+1)])\n",
    "    k = min(len(relevant), k)\n",
    "    dsg_at_k = 0\n",
    "    for k in range(1, k+1):\n",
    "        dsg_at_k += int(relevant[k-1] == predicted[k-1])/np.log2(k+1)\n",
    "    return dsg_at_k/idsg_at_k\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Коллаборативная фильтрация (User2User)\n",
    "\n",
    "\n",
    "В качестве функции схожести будет использовано две метрики:\n",
    "\n",
    "1. Корреляция Пирсона $$s(u, v) = \\frac{\\sum_{i \\in I_u \\cap I_v} r_{ui}r_{vi}}{\\sqrt{\\sum_{i \\in I_u} r_{ui} ^2}\\sqrt{\\sum_{i \\in I_v} r_{vi}^2}} $$\n",
    "\n",
    "2. Мера Жаккара\n",
    "\n",
    "$$ s(u, v) = \\frac{|I_u \\cap I_v|}{|I_u \\cup I_v|} $$\n",
    "\n",
    "\n",
    "Корреляция Пирсона немного видоизменена, чтобы подходить под текущую задачу.</br> \n",
    "квадрат в формуле можно опустить т.к. рейтинг принимает два значения 0 или 1 (квадрат которых 0 или 1)\n",
    "\n",
    "Во всех формулах \n",
    "* $I_u$ - множество продуктов, купленных пользователем $u$.\n",
    "* $r_{ui}$ - покупал ли пользователь $u$ продукт $i$ (0 или 1).\n",
    "\n",
    "Множество соседей определим как $$N(u) = \\{ v \\in U \\setminus \\{u\\} \\mid s(u, v) > \\alpha\\},$$ где $\\alpha \\, - $ гиперпараметр.\n",
    "\n",
    "\n",
    "\n",
    "Для агрегации используется следующая формула:\n",
    "$$\n",
    "\\hat{r}_{ui} = \\frac{\\sum_{v \\in N(u)} s(u, v) r_{vi}}{\\sum_{v \\in N(u)} |s(u, v)|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(rating_matrix, user_vector):\n",
    "    \"\"\"\n",
    "        Функция расчета корреляции Пирсона\n",
    "    \"\"\"\n",
    "    # Числитель\n",
    "    numerator = rating_matrix.dot(user_vector.T)\n",
    "    n = rating_matrix.shape[1]\n",
    "    # Знаменатель\n",
    "    denominator = np.sqrt(user_vector.dot(np.ones(shape=(n, 1)))) * np.sqrt(rating_matrix.dot(np.ones(shape=(n, 1))))\n",
    "    ans = numerator / denominator\n",
    "    return ans.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_union(rating_matrix, uid: int = 0):\n",
    "#     unions = []\n",
    "#     for i in range(rating_matrix.shape[0]):\n",
    "#         ans = rating_matrix[i] + rating_matrix[uid]\n",
    "#         union = sum(np.where(ans.toarray()[0] >= 1, 1, 0))\n",
    "#         unions.append(union)\n",
    "#     return np.array(unions)\n",
    "\n",
    "\n",
    "# def jaccard(ratings_matrix, uid: int):\n",
    "#     # Пересечение \n",
    "#     inter = rating_matrix.dot(rating_matrix[uid].T)\n",
    "#     union = get_union(rating_matrix=rating_matrix, uid=0)\n",
    "    \n",
    "#     return inter / union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User2User():\n",
    "\n",
    "    def __init__(self, rating_matrix, similarity_func, encoder):\n",
    "        assert similarity_func in [pearson]\n",
    "        self.rating_matrix = rating_matrix\n",
    "        self.similarity_func = similarity_func\n",
    "        self.alpha = 0.02\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def predict(self, users_to_recommend: list, n_jobs: int = 3, k: int = 10):\n",
    "        \"\"\"\n",
    "            Параллельное вычисление рекомендаций для пользователей\n",
    "        \"\"\"\n",
    "        predictions = Parallel(n_jobs=3)(delayed(self.recommend)(uid=uid, k=k) for uid in users_to_recommend)\n",
    "        return predictions\n",
    "\n",
    "    def cold_start(self):\n",
    "        \"\"\"\n",
    "            Функция холодного старта\n",
    "            возвращает популярные продукты по убываюнию\n",
    "        \"\"\"\n",
    "        return np.argsort(rating_matrix.T.dot(np.ones(shape=(rating_matrix.shape[1], 1))).T)[::-1]\n",
    "\n",
    "    def recommend(self,uid: int, k: int):\n",
    "        \"\"\"\n",
    "            Расчет рекомендаций\n",
    "        \"\"\"\n",
    "\n",
    "        # Если ранее такого пользователя не было, то применяется холодный старт\n",
    "        try:\n",
    "            uid = self.encoder.transform(np.array([uid]))\n",
    "        except:\n",
    "            return self.cold_start()\n",
    "\n",
    "        # Вектор пользователя\n",
    "        user_vector = self.rating_matrix[uid]\n",
    "        # Расчет схожести пользователя с остальными пользователями\n",
    "        sim_vector = self.similarity_func(rating_matrix=self.rating_matrix, user_vector=user_vector)\n",
    "        # Индексы со значением функции схожести выше порогового значения\n",
    "        collab_ids = np.where(sim_vector >= self.alpha)[0]\n",
    "        # Исключается индекс самого объекта\n",
    "        collab_ids = collab_ids[collab_ids != uid]\n",
    "        # Расчет рекомендации \n",
    "        sum_of_suvs = np.sum(sim_vector[collab_ids])\n",
    "        suv_matrix = (self.rating_matrix[collab_ids, ].T.dot(sim_vector[collab_ids])).T/sum_of_suvs\n",
    "        # rui_est = np.sum(suv_matrix, axis=0)\n",
    "\n",
    "        return np.argsort(suv_matrix[0])[::-1][:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = User2User(rating_matrix=rating_matrix, \n",
    "                  similarity_func=pearson, \n",
    "                  encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пользователи с их релевантными покупками\n",
    "relevant = (test_df.sort_values(by=[\"user_id\", \"add_to_cart_order\"])\n",
    "            .groupby(['user_id'])\n",
    "            .agg({'product_id': 'unique'})['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20min 57s\n",
      "Wall time: 3h 12min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Рекомендации\n",
    "predict = model.predict(relevant.index, n_jobs=3, k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценки качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "relevant = relevant.to_list()\n",
    "metrics[\"MAP@k\"] = map_at_k(relevant=relevant, predicted=predict, k=10)\n",
    "metrics[\"MNAP@k\"] = mnap_at_k(relevant=relevant, predicted=predict, k=10)\n",
    "metrics[\"Hitrate@k\"] = hitrate_at_k(relevant=relevant, predicted=predict, k=10)\n",
    "sum_ndsg = 0\n",
    "sum_precision = 0\n",
    "for user in range(len(relevant)):\n",
    "    rel = relevant[user]\n",
    "    pred = predict[user]\n",
    "    sum_ndsg += ndsg_at_k(relevant=rel, predicted=pred, k=10)\n",
    "    sum_precision += precision_at_k(relevant=rel, predicted=pred, k=10)\n",
    "metrics[\"AVG_nDSG@k\"] = sum_ndsg/len(relevant)\n",
    "metrics[\"AVG_Precision@k\"] = sum_precision/len(relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@k': 0.0072773837301589915,\n",
       " 'MNAP@k': 0.013485420247542781,\n",
       " 'Hitrate@k': 0.50501,\n",
       " 'AVG_nDSG@k': 0.01749793338955469,\n",
       " 'AVG_Precision@k': 0.07412700000002749}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
